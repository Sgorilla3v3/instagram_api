import os
import argparse
import logging
import json
import time
import requests
from dotenv import load_dotenv
from typing import List, Dict, Any
from tqdm import tqdm   # ì§„í–‰ë°” ë¼ì´ë¸ŒëŸ¬ë¦¬

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

ACCESS_TOKEN = os.getenv("ACCESS_TOKEN")
IG_USER_ID   = os.getenv("IG_USER_ID")
FIELD_PARAMS = os.getenv("FIELD_PARAMS")

# metricsë¥¼ envì—ì„œ ì½ê³  ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
INSIGHT_METRICS       = os.getenv("INSIGHT_METRICS")
INSIGHT_METRICS_STORY = os.getenv("INSIGHT_METRICS_STORY")
INSIGHT_METRICS_REELS = os.getenv("INSIGHT_METRICS_REELS")
INSIGHT_METRICS_VIDEO = os.getenv("INSIGHT_METRICS_VIDEO")

OUTPUT_DIR = os.getenv("OUTPUT_DIR")
os.makedirs(OUTPUT_DIR, exist_ok=True)

# ë¡œê±° ì„¤ì •
logger = logging.getLogger("ig_contents")
logger.setLevel(logging.INFO)
fh = logging.FileHandler(os.path.join(OUTPUT_DIR, "my_contents.log"), encoding="utf-8")
fh.setFormatter(logging.Formatter('%(asctime)s %(levelname)s %(message)s'))
logger.addHandler(fh)
ch = logging.StreamHandler()
ch.setFormatter(logging.Formatter('%(levelname)s: %(message)s'))
logger.addHandler(ch)


def get_metrics_for_post(post: dict) -> str:
    """ë¯¸ë””ì–´ íƒ€ì…ì— ë”°ë¼ metrics ì„¸íŠ¸ ë°˜í™˜"""
    mtype = post.get("media_type")
    product = post.get("media_product_type")

    if product == "STORY":
        return INSIGHT_METRICS_STORY
    elif product == "REELS":
        return INSIGHT_METRICS_REELS
    elif mtype == "VIDEO":
        return INSIGHT_METRICS_VIDEO
    else:  # IMAGE, CAROUSEL_ALBUM ë“±
        return INSIGHT_METRICS


def fetch_user_media_all(limit: int = 100) -> List[Dict[str, Any]]:
    """
    Instagram ë¹„ì¦ˆë‹ˆìŠ¤ ê³„ì •ì˜ ëª¨ë“  ë¯¸ë””ì–´ë¥¼ í˜ì´ì§• ì²˜ë¦¬í•˜ë©° ê°€ì ¸ì˜¤ê¸°
    """
    base_url = f"https://graph.facebook.com/v23.0/{IG_USER_ID}/media"
    params = {
        "fields": FIELD_PARAMS,
        "access_token": ACCESS_TOKEN,
        "limit": limit,
    }

    all_posts = []
    next_url, next_params = base_url, params

    while next_url:
        for attempt in range(3):
            try:
                if next_params:
                    resp = requests.get(next_url, params=next_params, timeout=10)
                else:
                    resp = requests.get(next_url, timeout=10)

                if resp.status_code == 429:
                    logger.warning("âš ï¸ Rate limit ì´ˆê³¼ â†’ 60ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„")
                    time.sleep(60)
                    continue

                resp.raise_for_status()
                break
            except requests.RequestException as e:
                logger.warning(f"ìš”ì²­ ì—ëŸ¬, ì¬ì‹œë„ {attempt+1}/3: {e}")
                time.sleep(2 ** attempt)
        else:
            logger.error("3ë²ˆ ì¬ì‹œë„ í›„ì—ë„ ì‹¤íŒ¨ â†’ ì¤‘ë‹¨")
            return all_posts

        payload = resp.json()
        data = payload.get("data", [])
        all_posts.extend(data)

        logger.info(f"í˜ì´ì§€ ìˆ˜ì§‘ ì™„ë£Œ: {len(data)}ê°œ, ëˆ„ì  {len(all_posts)}ê°œ")

        paging = payload.get("paging", {})
        next_url = paging.get("next")
        next_params = None

    return all_posts


def fetch_insights(media_id: str, metrics: str) -> dict:
    """
    íŠ¹ì • ë¯¸ë””ì–´ì˜ insights ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    """
    url = f"https://graph.facebook.com/v23.0/{media_id}/insights"
    params = {"metric": metrics, "access_token": ACCESS_TOKEN}
    try:
        resp = requests.get(url, params=params, timeout=10)
        resp.raise_for_status()
        return resp.json()
    except requests.RequestException as e:
        logger.error(f"âŒ insights ìš”ì²­ ì‹¤íŒ¨ (media_id={media_id}): {e}")
        return {"error": str(e)}


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Fetch all Instagram business account media with insights"
    )
    parser.add_argument(
        "--output", "-o",
        default="all_user_media_with_insights.json",
        help="ì €ì¥í•  JSON íŒŒì¼ëª…"
    )
    args = parser.parse_args()

    if not ACCESS_TOKEN or not IG_USER_ID:
        parser.error("í™˜ê²½ë³€ìˆ˜ ACCESS_TOKEN ë° IG_USER_IDë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")

    logger.info("â–¶ï¸ ì „ì²´ ë¯¸ë””ì–´ ìˆ˜ì§‘ ì‹œì‘â€¦")
    posts = fetch_user_media_all()
    logger.info(f"âœ… ì´ {len(posts)}ê°œ ë¯¸ë””ì–´ ìˆ˜ì§‘ ì™„ë£Œ")

    # ê° ë¯¸ë””ì–´ insights ë¶™ì´ê¸° (ì§„í–‰ë°” ì¶œë ¥)
    results = []
    for post in tqdm(posts, desc="ğŸ“Š ë¯¸ë””ì–´ insights ìˆ˜ì§‘", unit="media"):
        metrics = get_metrics_for_post(post)
        insights = fetch_insights(post["id"], metrics)
        post["insights"] = insights.get("data", insights.get("error"))
        results.append(post)
        time.sleep(0.3)  # rate limit ë°©ì§€

    # JSON ì €ì¥
    output_path = os.path.join(OUTPUT_DIR, args.output)
    try:
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        logger.info(f"ğŸ’¾ '{output_path}' ì €ì¥ ì™„ë£Œ")
    except Exception as e:
        logger.error(f"âŒ JSON ì €ì¥ ì˜¤ë¥˜: {e}")
